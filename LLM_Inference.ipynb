{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b64778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:21:08.785820Z",
     "iopub.status.busy": "2023-10-10T13:21:08.784918Z",
     "iopub.status.idle": "2023-10-10T13:21:44.568584Z",
     "shell.execute_reply": "2023-10-10T13:21:44.567242Z"
    },
    "papermill": {
     "duration": 35.795372,
     "end_time": "2023-10-10T13:21:44.571125",
     "exception": false,
     "start_time": "2023-10-10T13:21:08.775753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./datasets-2.14.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.23.5)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (11.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.5.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (4.65.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2023.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (6.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.14.4) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.14.4) (1.16.0)\r\n",
      "Installing collected packages: datasets\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.1.0\r\n",
      "    Uninstalling datasets-2.1.0:\r\n",
      "      Successfully uninstalled datasets-2.1.0\r\n",
      "Successfully installed datasets-2.14.4\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/input/datasets-wheel/datasets-2.14.4-py3-none-any.whl /kaggle/working\n",
    "!pip install  /kaggle/working/datasets-2.14.4-py3-none-any.whl\n",
    "!cp /kaggle/input/backup-806/util_openbook.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc85cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:21:44.590126Z",
     "iopub.status.busy": "2023-10-10T13:21:44.589161Z",
     "iopub.status.idle": "2023-10-10T13:21:53.763380Z",
     "shell.execute_reply": "2023-10-10T13:21:53.762175Z"
    },
    "papermill": {
     "duration": 9.185662,
     "end_time": "2023-10-10T13:21:53.765718",
     "exception": false,
     "start_time": "2023-10-10T13:21:44.580056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.30.2\r\n",
      "    Uninstalling transformers-4.30.2:\r\n",
      "      Successfully uninstalled transformers-4.30.2\r\n",
      "Successfully installed transformers-4.31.0\r\n"
     ]
    }
   ],
   "source": [
    "# installing offline dependencies\n",
    "#!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "#!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n",
    "#!pip install -U /kaggle/working/sentence-transformers\n",
    "#!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n",
    "\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n",
    "#!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n",
    "#!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcc4728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:21:53.783712Z",
     "iopub.status.busy": "2023-10-10T13:21:53.783403Z",
     "iopub.status.idle": "2023-10-10T13:21:53.920490Z",
     "shell.execute_reply": "2023-10-10T13:21:53.919589Z"
    },
    "papermill": {
     "duration": 0.148367,
     "end_time": "2023-10-10T13:21:53.922599",
     "exception": false,
     "start_time": "2023-10-10T13:21:53.774232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from util_openbook import get_contexts, generate_openbook_output\n",
    "import pickle\n",
    "\n",
    "# get_contexts()\n",
    "# generate_openbook_output()\n",
    "\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3163b715",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-10T13:21:53.940581Z",
     "iopub.status.busy": "2023-10-10T13:21:53.940259Z",
     "iopub.status.idle": "2023-10-10T13:22:08.040818Z",
     "shell.execute_reply": "2023-10-10T13:22:08.039921Z"
    },
    "papermill": {
     "duration": 14.111861,
     "end_time": "2023-10-10T13:22:08.042979",
     "exception": false,
     "start_time": "2023-10-10T13:21:53.931118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import LongformerTokenizer, LongformerForMultipleChoice\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMultipleChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7c91d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:08.060702Z",
     "iopub.status.busy": "2023-10-10T13:22:08.060433Z",
     "iopub.status.idle": "2023-10-10T13:22:35.239031Z",
     "shell.execute_reply": "2023-10-10T13:22:35.237559Z"
    },
    "papermill": {
     "duration": 27.190619,
     "end_time": "2023-10-10T13:22:35.241697",
     "exception": false,
     "start_time": "2023-10-10T13:22:08.051078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/stem-wiki-cohere-no-emb /kaggle/working\n",
    "!cp -r /kaggle/input/all-paraphs-parsed-expanded /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeaaeb83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:35.421138Z",
     "iopub.status.busy": "2023-10-10T13:22:35.420617Z",
     "iopub.status.idle": "2023-10-10T13:22:35.589715Z",
     "shell.execute_reply": "2023-10-10T13:22:35.588712Z"
    },
    "papermill": {
     "duration": 0.230806,
     "end_time": "2023-10-10T13:22:35.592067",
     "exception": false,
     "start_time": "2023-10-10T13:22:35.361261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_AMP = True\n",
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP, init_scale=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e75b160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:35.869317Z",
     "iopub.status.busy": "2023-10-10T13:22:35.868806Z",
     "iopub.status.idle": "2023-10-10T13:22:35.963384Z",
     "shell.execute_reply": "2023-10-10T13:22:35.962136Z"
    },
    "papermill": {
     "duration": 0.167544,
     "end_time": "2023-10-10T13:22:35.967114",
     "exception": false,
     "start_time": "2023-10-10T13:22:35.799570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SplitList(mylist, chunk_size):\n",
    "    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n",
    "\n",
    "def get_relevant_documents_parsed(df_valid,df_chunk_size=700):\n",
    "    df_chunk_size=df_chunk_size\n",
    "    paraphs_parsed_dataset = load_from_disk(\"/kaggle/working/all-paraphs-parsed-expanded\")\n",
    "    modified_texts = paraphs_parsed_dataset.map(lambda example:\n",
    "                                             {'temp_text':\n",
    "                                              f\"{example['title']} {example['section']} {example['text']}\".replace('\\n',\" \").replace(\"'\",\"\")},\n",
    "                                             num_proc=2)[\"temp_text\"]\n",
    "    \n",
    "    all_articles_indices = []\n",
    "    all_articles_values = []\n",
    "    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n",
    "        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n",
    "    \n",
    "        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n",
    "        all_articles_indices.append(articles_indices)\n",
    "        all_articles_values.append(merged_top_scores)\n",
    "        \n",
    "    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n",
    "    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n",
    "    \n",
    "    top_per_query = article_indices_array.shape[1]\n",
    "    articles_flatten = [(\n",
    "                         articles_values_array[index],\n",
    "                         paraphs_parsed_dataset[idx.item()][\"title\"],\n",
    "                         paraphs_parsed_dataset[idx.item()][\"text\"],\n",
    "                        )\n",
    "                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n",
    "    retrieved_articles = SplitList(articles_flatten, top_per_query)\n",
    "    return retrieved_articles\n",
    "\n",
    "\n",
    "\n",
    "def get_relevant_documents(df_valid,df_chunk_size=800):\n",
    "    #df_chunk_size=800\n",
    "    \n",
    "    cohere_dataset_filtered = load_from_disk(\"/kaggle/working/stem-wiki-cohere-no-emb\")\n",
    "    modified_texts = cohere_dataset_filtered.map(lambda example:\n",
    "                                             {'temp_text':\n",
    "                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"',\"\")},\n",
    "                                             num_proc=2)[\"temp_text\"]\n",
    "    \n",
    "    all_articles_indices = []\n",
    "    all_articles_values = []\n",
    "    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n",
    "        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n",
    "    \n",
    "        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n",
    "        all_articles_indices.append(articles_indices)\n",
    "        all_articles_values.append(merged_top_scores)\n",
    "        \n",
    "    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n",
    "    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n",
    "    \n",
    "    top_per_query = article_indices_array.shape[1]\n",
    "    articles_flatten = [(\n",
    "                         articles_values_array[index],\n",
    "                         cohere_dataset_filtered[idx.item()][\"title\"],\n",
    "                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n",
    "                        )\n",
    "                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n",
    "    retrieved_articles = SplitList(articles_flatten, top_per_query)\n",
    "    return retrieved_articles\n",
    "\n",
    "\n",
    "\n",
    "def retrieval(df_valid, modified_texts):\n",
    "    \n",
    "    corpus_df_valid = df_valid.apply(lambda row:\n",
    "                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n",
    "                                     axis=1).values\n",
    "    vectorizer1 = TfidfVectorizer(ngram_range=(1,6),\n",
    "                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "                                 stop_words=stop_words)\n",
    "    vectorizer1.fit(corpus_df_valid)\n",
    "    vocab_df_valid = vectorizer1.get_feature_names_out()\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,6),\n",
    "                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "                                 stop_words=stop_words,\n",
    "                                 vocabulary=vocab_df_valid)\n",
    "    vectorizer.fit(modified_texts[:500000])\n",
    "    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n",
    "    \n",
    "    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n",
    "\n",
    "    chunk_size = 100000\n",
    "    top_per_chunk = 10\n",
    "    top_per_query = 10\n",
    "\n",
    "    all_chunk_top_indices = []\n",
    "    all_chunk_top_values = []\n",
    "\n",
    "    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n",
    "        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n",
    "        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n",
    "        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n",
    "        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n",
    "\n",
    "        all_chunk_top_indices.append(chunk_top_indices + idx)\n",
    "        all_chunk_top_values.append(chunk_top_values)\n",
    "\n",
    "    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n",
    "    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n",
    "    \n",
    "    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n",
    "    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n",
    "    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n",
    "    \n",
    "    return articles_indices, merged_top_scores\n",
    "\n",
    "\n",
    "def prepare_answering_input(\n",
    "        tokenizer, \n",
    "        question,  \n",
    "        options,   \n",
    "        context,   \n",
    "        max_seq_length=4096,\n",
    "    ):\n",
    "    c_plus_q   = str(context) + ' ' + tokenizer.bos_token + ' ' + str(question)\n",
    "    c_plus_q_4 = [str(c_plus_q)] * len(options)\n",
    "    tokenized_examples = tokenizer(\n",
    "        c_plus_q_4, options,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"longest\",\n",
    "        truncation=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = tokenized_examples['input_ids'].unsqueeze(0)\n",
    "    attention_mask = tokenized_examples['attention_mask'].unsqueeze(0)\n",
    "    token_type_ids = tokenized_examples['token_type_ids'].unsqueeze(0)\n",
    "    example_encoded = {\n",
    "        \"input_ids\": input_ids.to('cuda'),\n",
    "        \"attention_mask\": attention_mask.to('cuda'),\n",
    "        'token_type_ids': token_type_ids.to('cuda')\n",
    "    }\n",
    "    return example_encoded\n",
    "\n",
    "\n",
    "def prepare_answering_input2(\n",
    "        tokenizer, \n",
    "        question,  \n",
    "        options,   \n",
    "        context,   \n",
    "        max_seq_length=4096,\n",
    "    ):\n",
    "    c_plus_q   = str(context) + ' ' + tokenizer.bos_token + ' ' + str(question)\n",
    "    c_plus_q_4 = [str(c_plus_q)] * len(options)\n",
    "    tokenized_examples = tokenizer(\n",
    "        c_plus_q_4, options,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"longest\",\n",
    "        truncation=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    #new_dict = dict()\n",
    "    #new_dict['input_ids'] = torch.zeros([5, max_seq_length])\n",
    "\n",
    "    if tokenized_examples['input_ids'].shape[1]>max_seq_length:\n",
    "        #if max_seq_length==512: print(tokenized_examples['input_ids'].shape[1], 'cut to len of 512')\n",
    "        start = tokenized_examples['input_ids'].shape[1] - max_seq_length\n",
    "        tokenized_examples['input_ids'] = tokenized_examples['input_ids'][:,start:]\n",
    "        tokenized_examples['attention_mask'] = tokenized_examples['attention_mask'][:,start:]\n",
    "        tokenized_examples['token_type_ids'] = tokenized_examples['token_type_ids'][:,start:]\n",
    "            \n",
    "    input_ids = tokenized_examples['input_ids'].unsqueeze(0)\n",
    "    attention_mask = tokenized_examples['attention_mask'].unsqueeze(0)\n",
    "    token_type_ids = tokenized_examples['token_type_ids'].unsqueeze(0)\n",
    "    example_encoded = {\n",
    "        \"input_ids\": input_ids.to('cuda'),\n",
    "        \"attention_mask\": attention_mask.to('cuda'),\n",
    "        'token_type_ids': token_type_ids.to('cuda')\n",
    "    }\n",
    "    return example_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5ce802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:36.089572Z",
     "iopub.status.busy": "2023-10-10T13:22:36.088945Z",
     "iopub.status.idle": "2023-10-10T13:22:36.107836Z",
     "shell.execute_reply": "2023-10-10T13:22:36.106771Z"
    },
    "papermill": {
     "duration": 0.091134,
     "end_time": "2023-10-10T13:22:36.110285",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.019151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = ['each', 'you', 'the', 'use', 'used',\n",
    "                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n",
    "                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n",
    "                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n",
    "                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n",
    "                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n",
    "                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n",
    "                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n",
    "                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n",
    "                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n",
    "                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n",
    "                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n",
    "                  'did', 'theirs', 'can', 'those',\n",
    "                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n",
    "                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n",
    "                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n",
    "                  'yours', 'but', 'being', \"wasn't\", 'be']\n",
    "# stop_words += ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'also', 'am', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'between', 'both', 'but', 'by', 'can', 'cannot', 'could', 'did', 'do', 'does', 'doing', 'during', 'each', 'for', 'from', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'if', 'in', 'into', 'is', 'it', 'its', 'itself', 'make', 'me', 'more', 'most', 'my', 'myself', 'no', 'nor', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'said', 'same', 'see', 'she', 'should', 'so', 'some', 'such', 'take', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'use', 'used', 'very', 'want', 'was', 'way', 'we', 'well', 'were', 'what', 'when', 'where', 'which', 'who', 'whom', 'why', 'will', 'with', 'would', 'you', 'your', 'yours', 'yourself', 'yourselves']\n",
    "# stop_words = list(set(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424d95df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:36.128294Z",
     "iopub.status.busy": "2023-10-10T13:22:36.128011Z",
     "iopub.status.idle": "2023-10-10T13:22:36.132121Z",
     "shell.execute_reply": "2023-10-10T13:22:36.131011Z"
    },
    "papermill": {
     "duration": 0.015018,
     "end_time": "2023-10-10T13:22:36.133904",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.118886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction import text\n",
    "# stop_words2 = text.ENGLISH_STOP_WORDS\n",
    "# stop_words = list(stop_words2.union(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df09f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:36.152448Z",
     "iopub.status.busy": "2023-10-10T13:22:36.151529Z",
     "iopub.status.idle": "2023-10-10T13:22:36.156080Z",
     "shell.execute_reply": "2023-10-10T13:22:36.155245Z"
    },
    "papermill": {
     "duration": 0.015629,
     "end_time": "2023-10-10T13:22:36.157754",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.142125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_valid = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\")\n",
    "# df_valid2 = pd.read_csv(\"/kaggle/input/stem-dataset-multiple-choice-questions/stem_dataset_multiple_choice_questions_20230825_063353.csv\")\n",
    "# df_valid2 = df_valid2[['prompt', 'A', 'B', 'C', 'D', 'E', 'answer']]\n",
    "# df_valid = pd.concat([df_valid, df_valid2])\n",
    "# print(df_valid.shape)\n",
    "# df_valid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727384f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:36.175319Z",
     "iopub.status.busy": "2023-10-10T13:22:36.174600Z",
     "iopub.status.idle": "2023-10-10T13:22:36.207126Z",
     "shell.execute_reply": "2023-10-10T13:22:36.205940Z"
    },
    "papermill": {
     "duration": 0.043341,
     "end_time": "2023-10-10T13:22:36.208959",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.165618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 7)\n"
     ]
    }
   ],
   "source": [
    "df_valid = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")\n",
    "print(df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed6c48c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:36.227021Z",
     "iopub.status.busy": "2023-10-10T13:22:36.226174Z",
     "iopub.status.idle": "2023-10-10T13:22:36.614664Z",
     "shell.execute_reply": "2023-10-10T13:22:36.613744Z"
    },
    "papermill": {
     "duration": 0.399103,
     "end_time": "2023-10-10T13:22:36.616518",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.217415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded to load pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_valid)==200:\n",
    "    try:\n",
    "        with open('/kaggle/input/llm-retrieved-pkls/parsed.pkl', 'rb') as f:\n",
    "            retrieved_articles_parsed = pickle.load(f)\n",
    "            \n",
    "        print('succeeded to load pkl')\n",
    "            \n",
    "    except:\n",
    "        retrieved_articles_parsed = get_relevant_documents_parsed(df_valid)\n",
    "        with open('parsed.pkl', 'wb') as f:\n",
    "            pickle.dump(retrieved_articles_parsed, f)\n",
    "            \n",
    "elif len(df_valid)==1200:\n",
    "    try:\n",
    "        with open('/kaggle/input/llm-retrieved-pkls/parsed1600.pkl', 'rb') as f:\n",
    "            retrieved_articles_parsed = pickle.load(f)\n",
    "        retrieved_articles_parsed = retrieved_articles_parsed[-1200:]\n",
    "        print('succeeded to load pkl')\n",
    "            \n",
    "    except:\n",
    "        seps = 600\n",
    "        retrieved_articles_parsed = get_relevant_documents_parsed(df_valid, seps)\n",
    "        with open('parsed1200.pkl', 'wb') as f:\n",
    "            pickle.dump(retrieved_articles_parsed, f)\n",
    "    \n",
    "else:\n",
    "    if len(df_valid)>2000:\n",
    "        seps = len(df_valid)//6 + 1\n",
    "    else:\n",
    "        seps = 600\n",
    "    retrieved_articles_parsed = get_relevant_documents_parsed(df_valid, seps)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de76b21",
   "metadata": {
    "papermill": {
     "duration": 0.008545,
     "end_time": "2023-10-10T13:22:36.633409",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.624864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4b1466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:36.652348Z",
     "iopub.status.busy": "2023-10-10T13:22:36.651317Z",
     "iopub.status.idle": "2023-10-10T13:22:36.976224Z",
     "shell.execute_reply": "2023-10-10T13:22:36.975296Z"
    },
    "papermill": {
     "duration": 0.336362,
     "end_time": "2023-10-10T13:22:36.977991",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.641629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded to load pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_valid)==200:\n",
    "    try:\n",
    "        with open('/kaggle/input/llm-retrieved-pkls/articles.pkl', 'rb') as f:\n",
    "            retrieved_articles = pickle.load(f)\n",
    "            \n",
    "        print('succeeded to load pkl')\n",
    "            \n",
    "    except:\n",
    "        retrieved_articles = get_relevant_documents(df_valid)\n",
    "        with open('articles.pkl', 'wb') as f:\n",
    "            pickle.dump(retrieved_articles, f)\n",
    "            \n",
    "elif len(df_valid)==1200:\n",
    "    try:\n",
    "        with open('/kaggle/input/llm-retrieved-pkls/articles1200.pkl', 'rb') as f:\n",
    "            retrieved_articles = pickle.load(f)\n",
    "        retrieved_articles = retrieved_articles[-1200:]\n",
    "        print('succeeded to load pkl')\n",
    "            \n",
    "    except:\n",
    "        seps = 600\n",
    "        retrieved_articles = get_relevant_documents(df_valid, seps)\n",
    "        with open('articles1200.pkl', 'wb') as f:\n",
    "            pickle.dump(retrieved_articles, f)\n",
    "            \n",
    "else:\n",
    "    if len(df_valid)>2000:\n",
    "        seps = len(df_valid)//5 + 1\n",
    "    else:\n",
    "        seps = 600\n",
    "    retrieved_articles = get_relevant_documents(df_valid, seps)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf50e6",
   "metadata": {
    "papermill": {
     "duration": 0.008735,
     "end_time": "2023-10-10T13:22:36.995378",
     "exception": false,
     "start_time": "2023-10-10T13:22:36.986643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0316c2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:37.014349Z",
     "iopub.status.busy": "2023-10-10T13:22:37.013527Z",
     "iopub.status.idle": "2023-10-10T13:22:37.019656Z",
     "shell.execute_reply": "2023-10-10T13:22:37.018743Z"
    },
    "papermill": {
     "duration": 0.017647,
     "end_time": "2023-10-10T13:22:37.021564",
     "exception": false,
     "start_time": "2023-10-10T13:22:37.003917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving quota to cut 200 to 10\n"
     ]
    }
   ],
   "source": [
    "if len(df_valid)==200:\n",
    "    df_valid = df_valid[:10]\n",
    "    print('saving quota to cut 200 to 10')\n",
    "    \n",
    "if len(df_valid)==1200:\n",
    "    df_valid = pd.concat([df_valid[:10],  df_valid[210:220]])\n",
    "    retrieved_articles = retrieved_articles[:10] + retrieved_articles[210:220]\n",
    "    retrieved_articles_parsed = retrieved_articles_parsed[:10] + retrieved_articles_parsed[210:220]\n",
    "    print('saving quota to cut 1200 to 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc151ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:37.039686Z",
     "iopub.status.busy": "2023-10-10T13:22:37.038968Z",
     "iopub.status.idle": "2023-10-10T13:22:37.061033Z",
     "shell.execute_reply": "2023-10-10T13:22:37.059929Z"
    },
    "papermill": {
     "duration": 0.033166,
     "end_time": "2023-10-10T13:22:37.062842",
     "exception": false,
     "start_time": "2023-10-10T13:22:37.029676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Gauss's law holds only for situations involvin...</td>\n",
       "      <td>Gauss's law holds in all cases, but it is most...</td>\n",
       "      <td>Gauss's law, which applies equally to all elec...</td>\n",
       "      <td>Gauss's law only holds for electric fields wit...</td>\n",
       "      <td>Gauss's law, which holds for all situations, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The dimension of an object in a CW complex is ...</td>\n",
       "      <td>The dimension of an object in a CW complex is ...</td>\n",
       "      <td>The dimension of an object in a CW complex is ...</td>\n",
       "      <td>The dimension of an object in a CW complex is ...</td>\n",
       "      <td>The dimension of an object in a CW complex dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The blocking temperature of an antiferromagnet...</td>\n",
       "      <td>The blocking temperature of an antiferromagnet...</td>\n",
       "      <td>The blocking temperature of an antiferromagnet...</td>\n",
       "      <td>The blocking temperature of an antiferromagnet...</td>\n",
       "      <td>The blocking temperature of an antiferromagnet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>What is the term used in astrophysics to descr...</td>\n",
       "      <td>Blueshifting</td>\n",
       "      <td>Redshifting</td>\n",
       "      <td>Reddening</td>\n",
       "      <td>Whitening</td>\n",
       "      <td>Yellowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>What is the role of axioms in a formal theory?</td>\n",
       "      <td>Basis statements called axioms form the founda...</td>\n",
       "      <td>Axioms are supplementary statements added to a...</td>\n",
       "      <td>Axioms are redundant statements that can be de...</td>\n",
       "      <td>The axioms in a theory are used for experiment...</td>\n",
       "      <td>The axioms in a formal theory are added to pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "5   5  Which of the following statements accurately d...   \n",
       "6   6  Which of the following statements accurately d...   \n",
       "7   7  Which of the following statements accurately d...   \n",
       "8   8  What is the term used in astrophysics to descr...   \n",
       "9   9     What is the role of axioms in a formal theory?   \n",
       "\n",
       "                                                   A  \\\n",
       "5  Gauss's law holds only for situations involvin...   \n",
       "6  The dimension of an object in a CW complex is ...   \n",
       "7  The blocking temperature of an antiferromagnet...   \n",
       "8                                       Blueshifting   \n",
       "9  Basis statements called axioms form the founda...   \n",
       "\n",
       "                                                   B  \\\n",
       "5  Gauss's law holds in all cases, but it is most...   \n",
       "6  The dimension of an object in a CW complex is ...   \n",
       "7  The blocking temperature of an antiferromagnet...   \n",
       "8                                        Redshifting   \n",
       "9  Axioms are supplementary statements added to a...   \n",
       "\n",
       "                                                   C  \\\n",
       "5  Gauss's law, which applies equally to all elec...   \n",
       "6  The dimension of an object in a CW complex is ...   \n",
       "7  The blocking temperature of an antiferromagnet...   \n",
       "8                                          Reddening   \n",
       "9  Axioms are redundant statements that can be de...   \n",
       "\n",
       "                                                   D  \\\n",
       "5  Gauss's law only holds for electric fields wit...   \n",
       "6  The dimension of an object in a CW complex is ...   \n",
       "7  The blocking temperature of an antiferromagnet...   \n",
       "8                                          Whitening   \n",
       "9  The axioms in a theory are used for experiment...   \n",
       "\n",
       "                                                   E  \n",
       "5  Gauss's law, which holds for all situations, i...  \n",
       "6  The dimension of an object in a CW complex dep...  \n",
       "7  The blocking temperature of an antiferromagnet...  \n",
       "8                                          Yellowing  \n",
       "9  The axioms in a formal theory are added to pro...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df79536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:37.081999Z",
     "iopub.status.busy": "2023-10-10T13:22:37.081537Z",
     "iopub.status.idle": "2023-10-10T13:22:37.089472Z",
     "shell.execute_reply": "2023-10-10T13:22:37.088586Z"
    },
    "papermill": {
     "duration": 0.019131,
     "end_time": "2023-10-10T13:22:37.091390",
     "exception": false,
     "start_time": "2023-10-10T13:22:37.072259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_valid['prompt'] = df_valid['prompt'].map(str)\n",
    "df_valid['A'] = df_valid['A'].map(str)\n",
    "df_valid['B'] = df_valid['B'].map(str)\n",
    "df_valid['C'] = df_valid['C'].map(str)\n",
    "df_valid['D'] = df_valid['D'].map(str)\n",
    "df_valid['E'] = df_valid['E'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aaf1ebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:22:37.110609Z",
     "iopub.status.busy": "2023-10-10T13:22:37.110362Z",
     "iopub.status.idle": "2023-10-10T13:23:17.034250Z",
     "shell.execute_reply": "2023-10-10T13:23:17.033283Z"
    },
    "papermill": {
     "duration": 39.935886,
     "end_time": "2023-10-10T13:23:17.036325",
     "exception": false,
     "start_time": "2023-10-10T13:22:37.100439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/kaggle/input/llm-cloud-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n",
    "model.eval()\n",
    "\n",
    "preds3 = []\n",
    "preds4 = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    \n",
    "    try:\n",
    "        columns = df_valid.iloc[index].values\n",
    "        question = columns[1]\n",
    "        options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n",
    "        \n",
    "        try:\n",
    "            context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "\n",
    "            inputs1 = prepare_answering_input(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context1,\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs1 = model(**inputs1)    \n",
    "                    losses1 = outputs1.logits[0].detach().cpu().numpy()\n",
    "                    probability1 = softmax(losses1, axis=-1)\n",
    "                \n",
    "        except:\n",
    "            print('error occurred while context1 inffering at: ', index)\n",
    "            print(inputs1['input_ids'][0].shape)\n",
    "            probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "            inputs2 = prepare_answering_input(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context2,\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs2 = model(**inputs2)\n",
    "                    losses2 = outputs2.logits[0].detach().cpu().numpy()\n",
    "                    probability2 = softmax(losses2, axis=-1)\n",
    "        \n",
    "        except:\n",
    "            print('error occurred while context2 inffering at:', index)\n",
    "            print(inputs2['input_ids'][0].shape)\n",
    "            probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "            \n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        \n",
    "        #del inputs1, inputs2\n",
    "        \n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    except:\n",
    "        print('unknown error occurred at:', index)\n",
    "        #probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        #probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    preds3.append(probability_1.reshape(1,5))\n",
    "    preds4.append(probability_2.reshape(1,5))\n",
    "    \n",
    "_ = gc.collect()\n",
    "_ = libc.malloc_trim(0)\n",
    "_ = torch.cuda.empty_cache()\n",
    "\n",
    "sub3 = np.concatenate(preds3, axis=0)\n",
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub3.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub3.csv')\n",
    "\n",
    "sub4 = np.concatenate(preds4, axis=0)\n",
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub4.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub4.csv')\n",
    "\n",
    "del preds3, preds4\n",
    "\n",
    "_ = gc.collect()\n",
    "_ = libc.malloc_trim(0)\n",
    "_ = torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a69ee",
   "metadata": {
    "papermill": {
     "duration": 0.009061,
     "end_time": "2023-10-10T13:23:17.054818",
     "exception": false,
     "start_time": "2023-10-10T13:23:17.045757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c79020d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:23:17.074395Z",
     "iopub.status.busy": "2023-10-10T13:23:17.074111Z",
     "iopub.status.idle": "2023-10-10T13:23:50.934408Z",
     "shell.execute_reply": "2023-10-10T13:23:50.933411Z"
    },
    "papermill": {
     "duration": 33.872594,
     "end_time": "2023-10-10T13:23:50.936521",
     "exception": false,
     "start_time": "2023-10-10T13:23:17.063927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/kaggle/input/fork-of-fork-of-how-to-train-open-book-mode-b5eb2d/model_v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n",
    "model.eval()\n",
    "\n",
    "preds5 = []\n",
    "preds6 = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    \n",
    "    try:\n",
    "        columns = df_valid.iloc[index].values\n",
    "        question = columns[1]\n",
    "        options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n",
    "        \n",
    "        try:\n",
    "            context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "\n",
    "            inputs1 = prepare_answering_input(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context1,\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                #with autocast:\n",
    "                outputs1 = model(**inputs1)    \n",
    "                losses1 = outputs1.logits[0].detach().cpu().numpy()\n",
    "                probability1 = softmax(losses1, axis=-1)\n",
    "\n",
    "                \n",
    "        except:\n",
    "            print('error occurred while context1 inffering at: ', index)\n",
    "            print(inputs1['input_ids'][0].shape)\n",
    "            probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "            inputs2 = prepare_answering_input(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context2,\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs2 = model(**inputs2)\n",
    "                    losses2 = outputs2.logits[0].detach().cpu().numpy()\n",
    "                    probability2 = softmax(losses2, axis=-1)\n",
    "        \n",
    "        except:\n",
    "            print('error occurred while context2 inffering at: ', index)\n",
    "            print(inputs2['input_ids'][0].shape)\n",
    "            probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "            \n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        \n",
    "        \n",
    "        \n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    except:\n",
    "        print('unknown error occurred at:', index)\n",
    "        #probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        #probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    preds5.append(probability_1.reshape(1,5))\n",
    "    preds6.append(probability_2.reshape(1,5))\n",
    "    \n",
    "_ = gc.collect()\n",
    "_ = libc.malloc_trim(0)\n",
    "_ = torch.cuda.empty_cache()\n",
    "\n",
    "sub5 = np.concatenate(preds5, axis=0)\n",
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub5.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub5.csv')\n",
    "\n",
    "sub6 = np.concatenate(preds6, axis=0)\n",
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub6.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub6.csv')\n",
    "\n",
    "del preds5, preds6\n",
    "\n",
    "_ = gc.collect()\n",
    "_ = libc.malloc_trim(0)\n",
    "_ = torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "333ed122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:23:50.958263Z",
     "iopub.status.busy": "2023-10-10T13:23:50.957369Z",
     "iopub.status.idle": "2023-10-10T13:24:11.841254Z",
     "shell.execute_reply": "2023-10-10T13:24:11.840132Z"
    },
    "papermill": {
     "duration": 20.896439,
     "end_time": "2023-10-10T13:24:11.843223",
     "exception": false,
     "start_time": "2023-10-10T13:23:50.946784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#itks model 0.840\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_conf, *, dropout=0.2, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Transformer\n",
    "        #self.config = AutoConfig.from_pretrained(model_conf)\n",
    "\n",
    "        self.transformer = AutoModelForMultipleChoice.from_config(model_conf)\n",
    "\n",
    "        #self._init_weights(self.fc, self.config)\n",
    "\n",
    "    def _init_weights(self, module, config):\n",
    "        module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        out = self.transformer(input_ids, attention_mask, token_type_ids=token_type_ids)\n",
    "        x = out['logits'] \n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "MODEL_DIR = '/kaggle/input/llmse-weights-private/llm_kaggle_exp16'\n",
    "CONF_PATH = MODEL_DIR + '/deberta-v3-large_config.pth'\n",
    "MODEL_PATH = MODEL_DIR + '/best_model_awp_fgm.pt'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR+'/tokenizer')\n",
    "config = torch.load(CONF_PATH)\n",
    "model = CustomModel(model_conf=config)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43e773de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:11.864673Z",
     "iopub.status.busy": "2023-10-10T13:24:11.864396Z",
     "iopub.status.idle": "2023-10-10T13:24:30.690921Z",
     "shell.execute_reply": "2023-10-10T13:24:30.689765Z"
    },
    "papermill": {
     "duration": 18.839252,
     "end_time": "2023-10-10T13:24:30.692779",
     "exception": false,
     "start_time": "2023-10-10T13:24:11.853527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "#predictions = []\n",
    "#submit_ids = []\n",
    "preds1 = []\n",
    "preds2 = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    \n",
    "    try:\n",
    "        columns = df_valid.iloc[index].values\n",
    "\n",
    "        question = columns[1]\n",
    "        options = [columns[2]+columns[3]+columns[4]+columns[5]+columns[6],\n",
    "                   columns[3]+columns[4]+columns[5]+columns[6]+columns[2],\n",
    "                   columns[4]+columns[5]+columns[6]+columns[2]+columns[3],\n",
    "                   columns[5]+columns[6]+columns[2]+columns[3]+columns[4],\n",
    "                   columns[6]+columns[2]+columns[3]+columns[4]+columns[5]]\n",
    "        try:\n",
    "            context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "            inputs1 = prepare_answering_input2(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context1,\n",
    "                )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs1 = model(**inputs1)    \n",
    "                    losses1 = outputs1.detach().cpu().numpy()\n",
    "                    probability1 = softmax(losses1, axis=-1)\n",
    "                \n",
    "        except:\n",
    "            print('error occurred while context1 inffering at: ', index)\n",
    "            print(inputs1['input_ids'][0].shape)\n",
    "            probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "            \n",
    "        try:\n",
    "            context2 = f\"{retrieved_articles_parsed[index][-4][2]}\\n{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "            inputs2 = prepare_answering_input2(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context2,\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs2 = model(**inputs2)\n",
    "                    losses2 = outputs2.detach().cpu().numpy()\n",
    "                    probability2 = softmax(losses2, axis=-1)\n",
    "        \n",
    "        except:\n",
    "            print('error occurred while context2 inffering at: ', index)\n",
    "            print(inputs2['input_ids'][0].shape)\n",
    "            probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "\n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        \n",
    "        del inputs1, inputs2\n",
    "        \n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    except:\n",
    "        print('unknown error occurred at:', index)\n",
    "        #probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        #probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    preds1.append(probability_1.reshape(1,5))\n",
    "    preds2.append(probability_2.reshape(1,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f536d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:30.714257Z",
     "iopub.status.busy": "2023-10-10T13:24:30.713987Z",
     "iopub.status.idle": "2023-10-10T13:24:31.012488Z",
     "shell.execute_reply": "2023-10-10T13:24:31.011781Z"
    },
    "papermill": {
     "duration": 0.311007,
     "end_time": "2023-10-10T13:24:31.014155",
     "exception": false,
     "start_time": "2023-10-10T13:24:30.703148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = gc.collect()\n",
    "_ = libc.malloc_trim(0)\n",
    "_ = torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc65863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:31.036403Z",
     "iopub.status.busy": "2023-10-10T13:24:31.035644Z",
     "iopub.status.idle": "2023-10-10T13:24:31.040149Z",
     "shell.execute_reply": "2023-10-10T13:24:31.039122Z"
    },
    "papermill": {
     "duration": 0.017344,
     "end_time": "2023-10-10T13:24:31.041918",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.024574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub1 = np.concatenate(preds1, axis=0)\n",
    "sub2 = np.concatenate(preds2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bda5fdcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:31.063444Z",
     "iopub.status.busy": "2023-10-10T13:24:31.063177Z",
     "iopub.status.idle": "2023-10-10T13:24:31.362999Z",
     "shell.execute_reply": "2023-10-10T13:24:31.361999Z"
    },
    "papermill": {
     "duration": 0.312496,
     "end_time": "2023-10-10T13:24:31.364841",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.052345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del preds1, preds2\n",
    "_=gc.collect()\n",
    "_=libc.malloc_trim(0)\n",
    "_=torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fea8c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:31.388310Z",
     "iopub.status.busy": "2023-10-10T13:24:31.388009Z",
     "iopub.status.idle": "2023-10-10T13:24:31.401605Z",
     "shell.execute_reply": "2023-10-10T13:24:31.400537Z"
    },
    "papermill": {
     "duration": 0.02679,
     "end_time": "2023-10-10T13:24:31.403481",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.376691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>D_prob</th>\n",
       "      <th>E_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.006531</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.975098</td>\n",
       "      <td>0.010597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.624512</td>\n",
       "      <td>0.123962</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>0.041046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.145386</td>\n",
       "      <td>0.086548</td>\n",
       "      <td>0.182983</td>\n",
       "      <td>0.008553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114380</td>\n",
       "      <td>0.872070</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.008720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125610</td>\n",
       "      <td>0.765137</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>0.039093</td>\n",
       "      <td>0.053741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A_prob    B_prob    C_prob    D_prob    E_prob\n",
       "0  0.004040  0.006531  0.003483  0.975098  0.010597\n",
       "1  0.624512  0.123962  0.187866  0.022095  0.041046\n",
       "2  0.576172  0.145386  0.086548  0.182983  0.008553\n",
       "3  0.114380  0.872070  0.002420  0.002403  0.008720\n",
       "4  0.125610  0.765137  0.016937  0.039093  0.053741"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub1.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub1.csv')\n",
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51085de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:31.426359Z",
     "iopub.status.busy": "2023-10-10T13:24:31.425816Z",
     "iopub.status.idle": "2023-10-10T13:24:31.438574Z",
     "shell.execute_reply": "2023-10-10T13:24:31.437573Z"
    },
    "papermill": {
     "duration": 0.025666,
     "end_time": "2023-10-10T13:24:31.440373",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.414707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>D_prob</th>\n",
       "      <th>E_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.569336</td>\n",
       "      <td>0.350342</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.016541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.156372</td>\n",
       "      <td>0.016541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144897</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A_prob    B_prob    C_prob    D_prob    E_prob\n",
       "0  0.001100  0.000308  0.001337  0.994141  0.002831\n",
       "1  0.569336  0.350342  0.040009  0.023010  0.016541\n",
       "2  0.534180  0.119873  0.172363  0.156372  0.016541\n",
       "3  0.144897  0.016937  0.832031  0.005047  0.001171\n",
       "4  0.001772  0.000354  0.000263  0.996094  0.001457"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub2.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub2.csv')\n",
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fcfdf11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:31.464392Z",
     "iopub.status.busy": "2023-10-10T13:24:31.463529Z",
     "iopub.status.idle": "2023-10-10T13:24:31.807432Z",
     "shell.execute_reply": "2023-10-10T13:24:31.806452Z"
    },
    "papermill": {
     "duration": 0.357036,
     "end_time": "2023-10-10T13:24:31.809524",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.452488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model\n",
    "_=gc.collect()\n",
    "_=libc.malloc_trim(0)\n",
    "_=torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b5fc0",
   "metadata": {
    "papermill": {
     "duration": 0.010758,
     "end_time": "2023-10-10T13:24:31.831666",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.820908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "949b02b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:31.853939Z",
     "iopub.status.busy": "2023-10-10T13:24:31.853606Z",
     "iopub.status.idle": "2023-10-10T13:24:53.136700Z",
     "shell.execute_reply": "2023-10-10T13:24:53.135598Z"
    },
    "papermill": {
     "duration": 21.29644,
     "end_time": "2023-10-10T13:24:53.138710",
     "exception": false,
     "start_time": "2023-10-10T13:24:31.842270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#itks model 0.840\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_conf, *, dropout=0.2, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Transformer\n",
    "        #self.config = AutoConfig.from_pretrained(model_conf)\n",
    "\n",
    "        self.transformer = AutoModelForMultipleChoice.from_config(model_conf)\n",
    "\n",
    "        #self._init_weights(self.fc, self.config)\n",
    "\n",
    "    def _init_weights(self, module, config):\n",
    "        module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        out = self.transformer(input_ids, attention_mask, token_type_ids=token_type_ids)\n",
    "        x = out['logits'] \n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "MODEL_DIR = '/kaggle/input/llmse-weights-private/llm_kaggle_exp17'\n",
    "CONF_PATH = MODEL_DIR + '/deberta-v3-large_config.pth'\n",
    "MODEL_PATH = MODEL_DIR + '/best_model_awp_fgm.pt'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR+'/tokenizer')\n",
    "config = torch.load(CONF_PATH)\n",
    "model = CustomModel(model_conf=config)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c137600b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:24:53.161966Z",
     "iopub.status.busy": "2023-10-10T13:24:53.161381Z",
     "iopub.status.idle": "2023-10-10T13:25:12.173843Z",
     "shell.execute_reply": "2023-10-10T13:25:12.172646Z"
    },
    "papermill": {
     "duration": 19.026243,
     "end_time": "2023-10-10T13:25:12.175691",
     "exception": false,
     "start_time": "2023-10-10T13:24:53.149448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "#predictions = []\n",
    "#submit_ids = []\n",
    "preds7 = []\n",
    "preds8 = []\n",
    "\n",
    "for index in tqdm(range(df_valid.shape[0])):\n",
    "    probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "    \n",
    "    try:\n",
    "        columns = df_valid.iloc[index].values\n",
    "\n",
    "        question = columns[1]\n",
    "        options = [columns[2]+columns[3]+columns[4]+columns[5]+columns[6],\n",
    "                   columns[3]+columns[4]+columns[5]+columns[6]+columns[2],\n",
    "                   columns[4]+columns[5]+columns[6]+columns[2]+columns[3],\n",
    "                   columns[5]+columns[6]+columns[2]+columns[3]+columns[4],\n",
    "                   columns[6]+columns[2]+columns[3]+columns[4]+columns[5]]\n",
    "        try:\n",
    "            context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "            inputs1 = prepare_answering_input2(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context1,\n",
    "                )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs1 = model(**inputs1)    \n",
    "                    losses1 = outputs1.detach().cpu().numpy()\n",
    "                    probability1 = softmax(losses1, axis=-1)\n",
    "\n",
    "        except:\n",
    "            print('error occurred while context1 inffering at: ', index)\n",
    "            print(inputs1['input_ids'][0].shape)\n",
    "            probability1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "            \n",
    "        try:\n",
    "            context2 = f\"{retrieved_articles_parsed[index][-4][2]}\\n{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n",
    "            inputs2 = prepare_answering_input2(\n",
    "                tokenizer=tokenizer, question=question,\n",
    "                options=options, context=context2,\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast:\n",
    "                    outputs2 = model(**inputs2)\n",
    "                    losses2 = outputs2.detach().cpu().numpy()\n",
    "                    probability2 = softmax(losses2, axis=-1)\n",
    "        \n",
    "        except:\n",
    "            print('error occurred while context2 inffering at: ', index)\n",
    "            print(inputs2['input_ids'][0].shape)\n",
    "            probability2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "\n",
    "        probability_1 = probability1\n",
    "        probability_2 = probability2\n",
    "        \n",
    "        #del inputs1, inputs2\n",
    "        \n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    except:\n",
    "        print('unknown error occurred at:', index)\n",
    "        #probability_1 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        #probability_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "        _ = gc.collect()\n",
    "        _ = libc.malloc_trim(0)\n",
    "        _ = torch.cuda.empty_cache()\n",
    "        \n",
    "    preds7.append(probability_1.reshape(1,5))\n",
    "    preds8.append(probability_2.reshape(1,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48ab2ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:12.199743Z",
     "iopub.status.busy": "2023-10-10T13:25:12.199460Z",
     "iopub.status.idle": "2023-10-10T13:25:12.499983Z",
     "shell.execute_reply": "2023-10-10T13:25:12.499063Z"
    },
    "papermill": {
     "duration": 0.314594,
     "end_time": "2023-10-10T13:25:12.501859",
     "exception": false,
     "start_time": "2023-10-10T13:25:12.187265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = gc.collect()\n",
    "_ = libc.malloc_trim(0)\n",
    "_ = torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70616bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:12.525576Z",
     "iopub.status.busy": "2023-10-10T13:25:12.525288Z",
     "iopub.status.idle": "2023-10-10T13:25:12.830153Z",
     "shell.execute_reply": "2023-10-10T13:25:12.829063Z"
    },
    "papermill": {
     "duration": 0.31877,
     "end_time": "2023-10-10T13:25:12.832069",
     "exception": false,
     "start_time": "2023-10-10T13:25:12.513299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub7 = np.concatenate(preds7, axis=0)\n",
    "sub8 = np.concatenate(preds8, axis=0)\n",
    "del preds7, preds8\n",
    "_=gc.collect()\n",
    "_=libc.malloc_trim(0)\n",
    "_=torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a534bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:12.858040Z",
     "iopub.status.busy": "2023-10-10T13:25:12.857414Z",
     "iopub.status.idle": "2023-10-10T13:25:12.871053Z",
     "shell.execute_reply": "2023-10-10T13:25:12.870036Z"
    },
    "papermill": {
     "duration": 0.027659,
     "end_time": "2023-10-10T13:25:12.872934",
     "exception": false,
     "start_time": "2023-10-10T13:25:12.845275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>D_prob</th>\n",
       "      <th>E_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007401</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.919434</td>\n",
       "      <td>0.036285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917480</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.023468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441650</td>\n",
       "      <td>0.203979</td>\n",
       "      <td>0.089478</td>\n",
       "      <td>0.256836</td>\n",
       "      <td>0.007755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113953</td>\n",
       "      <td>0.861816</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.010437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098267</td>\n",
       "      <td>0.676758</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.114197</td>\n",
       "      <td>0.078491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A_prob    B_prob    C_prob    D_prob    E_prob\n",
       "0  0.007401  0.026855  0.010117  0.919434  0.036285\n",
       "1  0.917480  0.013138  0.041199  0.004086  0.023468\n",
       "2  0.441650  0.203979  0.089478  0.256836  0.007755\n",
       "3  0.113953  0.861816  0.009064  0.004742  0.010437\n",
       "4  0.098267  0.676758  0.032349  0.114197  0.078491"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub7.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub7.csv')\n",
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ae39d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:12.898327Z",
     "iopub.status.busy": "2023-10-10T13:25:12.897935Z",
     "iopub.status.idle": "2023-10-10T13:25:12.910373Z",
     "shell.execute_reply": "2023-10-10T13:25:12.909466Z"
    },
    "papermill": {
     "duration": 0.026762,
     "end_time": "2023-10-10T13:25:12.912150",
     "exception": false,
     "start_time": "2023-10-10T13:25:12.885388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>D_prob</th>\n",
       "      <th>E_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.986328</td>\n",
       "      <td>0.011505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959961</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.008324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283936</td>\n",
       "      <td>0.184937</td>\n",
       "      <td>0.245117</td>\n",
       "      <td>0.254639</td>\n",
       "      <td>0.030975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234009</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.747559</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A_prob    B_prob    C_prob    D_prob    E_prob\n",
       "0  0.000515  0.000612  0.002104  0.986328  0.011505\n",
       "1  0.959961  0.014717  0.013138  0.003414  0.008324\n",
       "2  0.283936  0.184937  0.245117  0.254639  0.030975\n",
       "3  0.234009  0.011688  0.747559  0.004318  0.002588\n",
       "4  0.000919  0.000632  0.000333  0.996094  0.001893"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "df_prob = pd.DataFrame(zip(*sub8.T), index=df_valid.index, columns=prob_lables)\n",
    "df_prob.to_csv('sub8.csv')\n",
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df55a1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:12.937329Z",
     "iopub.status.busy": "2023-10-10T13:25:12.936620Z",
     "iopub.status.idle": "2023-10-10T13:25:13.284887Z",
     "shell.execute_reply": "2023-10-10T13:25:13.283784Z"
    },
    "papermill": {
     "duration": 0.362549,
     "end_time": "2023-10-10T13:25:13.287006",
     "exception": false,
     "start_time": "2023-10-10T13:25:12.924457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model\n",
    "_=gc.collect()\n",
    "_=libc.malloc_trim(0)\n",
    "_=torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a0e1c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.312306Z",
     "iopub.status.busy": "2023-10-10T13:25:13.312013Z",
     "iopub.status.idle": "2023-10-10T13:25:13.316664Z",
     "shell.execute_reply": "2023-10-10T13:25:13.315629Z"
    },
    "papermill": {
     "duration": 0.019093,
     "end_time": "2023-10-10T13:25:13.318471",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.299378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_prob = sub1 * 1 + sub2 * 1 + sub3 * 1 + sub4 * 1 + sub5 * 1 + sub6 * 1 + sub7 * 1 + sub8 * 1 # maximise MAP@3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6348cddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.343980Z",
     "iopub.status.busy": "2023-10-10T13:25:13.343092Z",
     "iopub.status.idle": "2023-10-10T13:25:13.351292Z",
     "shell.execute_reply": "2023-10-10T13:25:13.350268Z"
    },
    "papermill": {
     "duration": 0.022674,
     "end_time": "2023-10-10T13:25:13.353203",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.330529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 3, 2],\n",
       "       [2, 1, 0],\n",
       "       [3, 1, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_overall1 = np.argsort(-final_prob)[:,:3]\n",
    "predictions_overall1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71b817fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.378927Z",
     "iopub.status.busy": "2023-10-10T13:25:13.378072Z",
     "iopub.status.idle": "2023-10-10T13:25:13.385536Z",
     "shell.execute_reply": "2023-10-10T13:25:13.384621Z"
    },
    "papermill": {
     "duration": 0.021594,
     "end_time": "2023-10-10T13:25:13.387219",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.365625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['D', 'E', 'C'],\n",
       "       ['A', 'B', 'C'],\n",
       "       ['A', 'D', 'C'],\n",
       "       ['C', 'B', 'A'],\n",
       "       ['D', 'B', 'A']], dtype='<U1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_overall1]\n",
    "predictions_as_answer_letters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "001bf214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.411337Z",
     "iopub.status.busy": "2023-10-10T13:25:13.410493Z",
     "iopub.status.idle": "2023-10-10T13:25:13.417922Z",
     "shell.execute_reply": "2023-10-10T13:25:13.417051Z"
    },
    "papermill": {
     "duration": 0.021239,
     "end_time": "2023-10-10T13:25:13.419599",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.398360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D E C', 'A B C', 'A D C']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_string = df_valid['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]\n",
    "predictions_as_string[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dd598d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.444107Z",
     "iopub.status.busy": "2023-10-10T13:25:13.443777Z",
     "iopub.status.idle": "2023-10-10T13:25:13.456790Z",
     "shell.execute_reply": "2023-10-10T13:25:13.455986Z"
    },
    "papermill": {
     "duration": 0.027311,
     "end_time": "2023-10-10T13:25:13.458464",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.431153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = df_valid[['id', 'prediction']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "812fbb4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.483694Z",
     "iopub.status.busy": "2023-10-10T13:25:13.483145Z",
     "iopub.status.idle": "2023-10-10T13:25:13.492129Z",
     "shell.execute_reply": "2023-10-10T13:25:13.491081Z"
    },
    "papermill": {
     "duration": 0.024002,
     "end_time": "2023-10-10T13:25:13.494076",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.470074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D E C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A D C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C B A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>D B A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>B C E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>A C D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>D B E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>C B A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A E B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id prediction\n",
       "0   0      D E C\n",
       "1   1      A B C\n",
       "2   2      A D C\n",
       "3   3      C B A\n",
       "4   4      D B A\n",
       "5   5      B C E\n",
       "6   6      A C D\n",
       "7   7      D B E\n",
       "8   8      C B A\n",
       "9   9      A E B"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4423c7d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.520268Z",
     "iopub.status.busy": "2023-10-10T13:25:13.519643Z",
     "iopub.status.idle": "2023-10-10T13:25:13.524513Z",
     "shell.execute_reply": "2023-10-10T13:25:13.523616Z"
    },
    "papermill": {
     "duration": 0.019587,
     "end_time": "2023-10-10T13:25:13.526602",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.507015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c01c7348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T13:25:13.552260Z",
     "iopub.status.busy": "2023-10-10T13:25:13.551437Z",
     "iopub.status.idle": "2023-10-10T13:25:15.772461Z",
     "shell.execute_reply": "2023-10-10T13:25:15.771160Z"
    },
    "papermill": {
     "duration": 2.236443,
     "end_time": "2023-10-10T13:25:15.774842",
     "exception": false,
     "start_time": "2023-10-10T13:25:13.538399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf all-paraphs-parsed-expanded\n",
    "!rm -rf stem-wiki-cohere-no-emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e488bb3f",
   "metadata": {
    "papermill": {
     "duration": 0.011772,
     "end_time": "2023-10-10T13:25:15.799430",
     "exception": false,
     "start_time": "2023-10-10T13:25:15.787658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 258.652541,
   "end_time": "2023-10-10T13:25:19.007134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-10T13:21:00.354593",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
